{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kma-OIy4eydH"
      },
      "source": [
        "# Final Project: Machine Learning Operations (MLOps)\n",
        "- **Nama:** Muhammad Giat\n",
        "- **Email:** mhmmadgiat@gmail.com\n",
        "- **ID Dicoding:** mhmmadgiatt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWp6unU_eydK"
      },
      "source": [
        "### Mounting Google Drive\n",
        "Pada awal pipeline, Google Drive dipasang untuk memberikan akses ke file yang disimpan di dalamnya, seperti dataset dan file proyek yang diperlukan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz1GgS5WeydM",
        "outputId": "1f0d31dd-52e5-4dd4-e884-516f810696df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvcfxrh3eydP"
      },
      "source": [
        "### Ekstraksi Dataset dari File Zip\n",
        "Dataset yang diperlukan untuk pelatihan model dikemas dalam file zip yang diekstraksi ke dalam folder di Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vdkODFeFeydQ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path ke file zip di Google Drive\n",
        "zip_path = '/content/drive/My Drive/pipeline_2.zip'  # Sesuaikan nama file dan lokasi\n",
        "\n",
        "# Ekstraksi file zip ke folder di Colab\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/pipeline_2')\n",
        "\n",
        "# Pindah ke folder proyek\n",
        "os.chdir('/content/pipeline_2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tfx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZBXrr2Y4g4z8",
        "outputId": "a8f7c813-238f-4370-ea78-921ecd61b913"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tfx\n",
            "  Downloading tfx-1.15.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ml-pipelines-sdk==1.15.1 (from tfx)\n",
            "  Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.0)\n",
            "Collecting ml-metadata<1.16.0,>=1.15.0 (from tfx)\n",
            "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.10/dist-packages (from tfx) (24.2)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.5.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.25.5)\n",
            "Collecting docker<5,>=4.1 (from tfx)\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-apitools<1,>=0.5 (from tfx)\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-api-python-client<2,>=1.8 (from tfx)\n",
            "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.12.2)\n",
            "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting attrs<24,>=19.3.0 (from tfx)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: click<9,>=7 in /usr/local/lib/python3.10/dist-packages (from tfx) (8.1.7)\n",
            "Requirement already satisfied: google-api-core<3 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.73.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.25.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.68.1)\n",
            "Collecting keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4 (from tfx)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting kubernetes<13,>=10.0.1 (from tfx)\n",
            "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.26.4)\n",
            "Collecting pyarrow<11,>=10 (from tfx)\n",
            "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting scipy<1.13 (from tfx)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=6 in /usr/local/lib/python3.10/dist-packages (from tfx) (6.0.2)\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tfx)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-hub<0.16,>=0.15.0 (from tfx)\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow-data-validation<1.16.0,>=1.15.1 (from tfx)\n",
            "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting tensorflow-model-analysis<0.47.0,>=0.46.0 (from tfx)\n",
            "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting tensorflow-serving-api<2.16,>=2.15 (from tfx)\n",
            "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-transform<1.16.0,>=1.15.0 (from tfx)\n",
            "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tfx-bsl<1.16.0,>=1.15.1 (from tfx)\n",
            "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.10.12)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio<2,>=1.28.1 (from tfx)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (1.25.0)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.32.3)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.6)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (5.5.0)\n",
            "Collecting google-apitools<1,>=0.5 (from tfx)\n",
            "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.20.1)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.1)\n",
            "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_pubsublite-1.11.1-py2.py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.4.1)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_spanner-3.51.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_dlp-3.25.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.15.1)\n",
            "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_videointelligence-2.14.1-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_vision-3.8.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_recommendations_ai-0.10.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keyrings.google-artifactregistry-auth (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.16.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3->tfx) (1.66.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.8->tfx)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (1.13.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.10.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=3->tfx) (2.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4,>=2.7.3->tfx) (3.0.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (3.5.0)\n",
            "Collecting kt-legacy (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2024.8.30)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (75.1.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2.2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker<2,>=1.3.1->tfx) (5.9.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (2.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.37.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx) (1.4.2)\n",
            "Collecting pandas<2,>=1.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-metadata<1.16,>=1.15.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.7.1)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (11.0.0)\n",
            "Collecting rouge-score<2,>=0.1.2 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu<4,>=2.3 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tfx) (0.45.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx) (0.13.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.28.2)\n",
            "Collecting overrides<8.0.0,>=6.0.1 (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (0.5.2)\n",
            "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.18.2->apache-beam[gcp]<3,>=2.47->tfx) (1.6.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.2.0)\n",
            "Collecting jedi>=0.16 (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.13)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (2.27.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.10)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.9.0)\n",
            "Collecting colorama (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (3.1.3)\n",
            "Collecting protobuf<5,>=3.20.3 (from tfx)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: keyring in /usr/lib/python3/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (23.5.0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.10/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (1.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.2.2)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.8.4)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (0.49b2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.5.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.66.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (3.21.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.21.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.5.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.2.2)\n",
            "Downloading tfx-1.15.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_pipelines_sdk-1.15.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
            "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_dlp-3.25.1-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_pubsublite-1.11.1-py2.py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_recommendations_ai-0.10.14-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_spanner-3.51.0-py2.py3-none-any.whl (432 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.6/432.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_videointelligence-2.14.1-py2.py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_vision-3.8.1-py2.py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.9/486.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
            "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
            "Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: google-apitools, crcmod, dill, hdfs, pyfarmhash, rouge-score, docopt\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131014 sha256=77517a078cbbef128cdacb0d7a6e0ba0fe35e1c10ac5f19129bdbc634d8e63d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=f3f2d6361ea90c3e650b3c4f245691f4f1dac00828aaea7aeda410f1df8cb236\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=2874747cfcef5c7a6dda9733907e129c3be21b41d83e98d8292abd5b48d99fe5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=22829ab1fa515d482a40666da33e5302723e73e1f1ab9bd8765700fde75d578a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=88655 sha256=aa0eaa304160720a3caee995a33566df59ab2decd802dc9f4cb4d06fcb6af8e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=2a6ee30da67897fbe0bd36fc4d6c636d2f973e55d39ffc1dcb60f2cb57630d4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f6d10d3a2a7fa18b945853db42665063b888506880d847affd5a83b8483d228a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built google-apitools crcmod dill hdfs pyfarmhash rouge-score docopt\n",
            "Installing collected packages: sortedcontainers, pyfarmhash, kt-legacy, docopt, crcmod, zstandard, wrapt, uritemplate, tensorflow-estimator, scipy, redis, pydot, pyarrow, protobuf, portalocker, overrides, objsize, ml-dtypes, keras, jsonpickle, jedi, grpcio, fasteners, fastavro, dnspython, dill, colorama, cloudpickle, attrs, tensorflow-metadata, tensorflow-hub, sacrebleu, rouge-score, pymongo, pandas, ml-metadata, keras-tuner, hdfs, grpc-interceptor, docker, kubernetes, keyrings.google-artifactregistry-auth, grpcio-status, google-apitools, tensorboard, google-api-python-client, tensorflow, ml-pipelines-sdk, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-dlp, apache-beam, tensorflow-serving-api, google-cloud-pubsublite, tfx-bsl, tensorflow-transform, tensorflow-data-validation, tensorflow-model-analysis, tfx\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.0\n",
            "    Uninstalling jsonpickle-4.0.0:\n",
            "      Successfully uninstalled jsonpickle-4.0.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.13.1\n",
            "    Uninstalling tensorflow-metadata-1.13.1:\n",
            "      Successfully uninstalled tensorflow-metadata-1.13.1\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.16.1\n",
            "    Uninstalling tensorflow-hub-0.16.1:\n",
            "      Successfully uninstalled tensorflow-hub-0.16.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.62.3\n",
            "    Uninstalling grpcio-status-1.62.3:\n",
            "      Successfully uninstalled grpcio-status-1.62.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.151.0\n",
            "    Uninstalling google-api-python-client-2.151.0:\n",
            "      Successfully uninstalled google-api-python-client-2.151.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.61.0 attrs-23.2.0 cloudpickle-2.2.1 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docker-4.4.4 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-dlp-3.25.1 google-cloud-pubsublite-1.11.1 google-cloud-recommendations-ai-0.10.14 google-cloud-spanner-3.51.0 google-cloud-storage-2.19.0 google-cloud-videointelligence-2.14.1 google-cloud-vision-3.8.1 grpc-interceptor-0.15.4 grpcio-1.65.5 grpcio-status-1.48.2 hdfs-2.7.3 jedi-0.19.2 jsonpickle-3.4.2 keras-2.15.0 keras-tuner-1.4.7 keyrings.google-artifactregistry-auth-1.1.2 kt-legacy-1.0.5 kubernetes-12.0.1 ml-dtypes-0.3.2 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.1 objsize-0.7.0 overrides-7.7.0 pandas-1.5.3 portalocker-3.0.0 protobuf-3.20.3 pyarrow-10.0.1 pydot-1.4.2 pyfarmhash-0.3.2 pymongo-4.10.1 redis-5.2.1 rouge-score-0.1.2 sacrebleu-2.4.3 scipy-1.12.0 sortedcontainers-2.4.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-data-validation-1.15.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-metadata-1.15.0 tensorflow-model-analysis-0.46.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tfx-1.15.1 tfx-bsl-1.15.1 uritemplate-3.0.1 wrapt-1.14.1 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2579f733996846fd82dcdfc37586a176"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjE4nAjEh-k8",
        "outputId": "17600da1-9245-4166-ff60-8f17d9c515e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting modules\n",
            "  Downloading modules-1.0.0.tar.gz (525 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: modules\n",
            "  Building wheel for modules (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modules: filename=modules-1.0.0-py3-none-any.whl size=1198 sha256=3c9684cd9f1d94dad3c293768000789fb287aae30aa8699f6185401e7947383a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/1b/5a/0e7760d483cf2ac6001c9df78809f16feb9632607248e3ab78\n",
            "Successfully built modules\n",
            "Installing collected packages: modules\n",
            "Successfully installed modules-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbNrI3MoeydR"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/pipeline_2')"
      ],
      "metadata": {
        "id": "XpfuK-dCpRvV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek isi direktori\n",
        "!ls /content/pipeline_2/modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrNYWKPVuKl1",
        "outputId": "b887a4bb-5dd6-44d9-a8bb-5204e024da14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "components.py  hate_trainer.py\thate_transform.py  __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "module_path = '/content/pipeline_2/modules/components.py'\n",
        "module_name = 'modules.components'\n",
        "\n",
        "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
        "module = importlib.util.module_from_spec(spec)\n",
        "sys.modules[module_name] = module\n",
        "spec.loader.exec_module(module)\n",
        "\n",
        "# Sekarang gunakan fungsi dari modul\n",
        "init_components = module.init_components"
      ],
      "metadata": {
        "id": "QL2GIWRxucAj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nUoMTznveydS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pdr\n",
        "import pandas as pd\n",
        "from typing import Text\n",
        "from absl import logging\n",
        "from tfx.orchestration import metadata, pipeline\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "from sklearn.utils import resample\n",
        "from modules.components import init_components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIeAw9vpeydS"
      },
      "source": [
        "# Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mLNApDLYeydT",
        "outputId": "f7c90d6b-52e0-4c84-b32e-d602875867f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          image_name                                           sentence  \\\n",
              "0    LJ3r8Gy.jpg.png  OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...   \n",
              "1        qDnIIHA.png  2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...   \n",
              "2        1JQk5NF.png                o shit waddup ! BERNIE SANDERS COM    \n",
              "3          iMMNq.png  `` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...   \n",
              "4        jAi3iI1.png  Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...   \n",
              "..               ...                                                ...   \n",
              "738      iutC6Qy.png  Pussy almost brings down Trump Weiner knocks o...   \n",
              "739      yGHKtzg.png  CLINTON SAID SHE B BRINGING BACK RUGRATIS AM G...   \n",
              "740      phyDxAb.png  2 hrs THAT AwKWARD MoMENT wHEN ... I. BERNIE S...   \n",
              "741      Qj9x2wz.png  FOR HILLARY BLOOD ON YOUR HANDS Stop Voting ou...   \n",
              "742      1f2zSW8.png  Debate Site St. Louis 3:21 PM CT HARA ENTSPIZZ...   \n",
              "\n",
              "            label  \n",
              "0    Non-offensiv  \n",
              "1       offensive  \n",
              "2       offensive  \n",
              "3    Non-offensiv  \n",
              "4    Non-offensiv  \n",
              "..            ...  \n",
              "738     offensive  \n",
              "739     offensive  \n",
              "740  Non-offensiv  \n",
              "741     offensive  \n",
              "742  Non-offensiv  \n",
              "\n",
              "[743 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba9469f8-36b0-46a6-87b1-cd63e85982b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ3r8Gy.jpg.png</td>\n",
              "      <td>OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qDnIIHA.png</td>\n",
              "      <td>2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1JQk5NF.png</td>\n",
              "      <td>o shit waddup ! BERNIE SANDERS COM</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iMMNq.png</td>\n",
              "      <td>`` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jAi3iI1.png</td>\n",
              "      <td>Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>iutC6Qy.png</td>\n",
              "      <td>Pussy almost brings down Trump Weiner knocks o...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>yGHKtzg.png</td>\n",
              "      <td>CLINTON SAID SHE B BRINGING BACK RUGRATIS AM G...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>phyDxAb.png</td>\n",
              "      <td>2 hrs THAT AwKWARD MoMENT wHEN ... I. BERNIE S...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>Qj9x2wz.png</td>\n",
              "      <td>FOR HILLARY BLOOD ON YOUR HANDS Stop Voting ou...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1f2zSW8.png</td>\n",
              "      <td>Debate Site St. Louis 3:21 PM CT HARA ENTSPIZZ...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>743 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba9469f8-36b0-46a6-87b1-cd63e85982b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba9469f8-36b0-46a6-87b1-cd63e85982b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba9469f8-36b0-46a6-87b1-cd63e85982b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8431f15-41ca-45b4-ace9-2253ab3917bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8431f15-41ca-45b4-ace9-2253ab3917bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8431f15-41ca-45b4-ace9-2253ab3917bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9f0f4561-0f01-4e60-a2ff-31aded3f3d0c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9f0f4561-0f01-4e60-a2ff-31aded3f3d0c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 743,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 743,\n        \"samples\": [\n          \"xyi7yMK.png\",\n          \"mHAg22Y.png\",\n          \"WQjyHN1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 743,\n        \"samples\": [\n          \"Donald J. Trump Follow @ realDonald Trump have never seen a thin person drinking Diet Coke RETWEETS LIKES 45,006 44,801 11:43 AM 14 Oct 2012 \",\n          \"THIS IS A WALLINSIDE A NAZI GAS CHAMBER dwebs WHEN A DEMOCRAT MENTIONS GUN CONTROL REMEMBER THIS PICTURE \",\n          \"TRUMP OR HILLARY ? IM COMING , HARAMBE ! \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"offensive\",\n          \"Non-offensiv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv('/content/pipeline_2/Data/dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gSTzrNdfeydV",
        "outputId": "b0705692-ba80-4b19-dc43-47cfba3549df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        image_name                                           sentence  label\n",
              "0  LJ3r8Gy.jpg.png  OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...      0\n",
              "1      qDnIIHA.png  2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...      1\n",
              "2      1JQk5NF.png                o shit waddup ! BERNIE SANDERS COM       1\n",
              "3        iMMNq.png  `` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...      0\n",
              "4      jAi3iI1.png  Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e2b78bc-b3a0-4400-bb9f-1655961b8704\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ3r8Gy.jpg.png</td>\n",
              "      <td>OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qDnIIHA.png</td>\n",
              "      <td>2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1JQk5NF.png</td>\n",
              "      <td>o shit waddup ! BERNIE SANDERS COM</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iMMNq.png</td>\n",
              "      <td>`` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jAi3iI1.png</td>\n",
              "      <td>Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e2b78bc-b3a0-4400-bb9f-1655961b8704')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e2b78bc-b3a0-4400-bb9f-1655961b8704 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e2b78bc-b3a0-4400-bb9f-1655961b8704');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2afa8009-d48f-45d6-aff8-6cccc82156a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2afa8009-d48f-45d6-aff8-6cccc82156a3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2afa8009-d48f-45d6-aff8-6cccc82156a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 743,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 743,\n        \"samples\": [\n          \"xyi7yMK.png\",\n          \"mHAg22Y.png\",\n          \"WQjyHN1.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 743,\n        \"samples\": [\n          \"Donald J. Trump Follow @ realDonald Trump have never seen a thin person drinking Diet Coke RETWEETS LIKES 45,006 44,801 11:43 AM 14 Oct 2012 \",\n          \"THIS IS A WALLINSIDE A NAZI GAS CHAMBER dwebs WHEN A DEMOCRAT MENTIONS GUN CONTROL REMEMBER THIS PICTURE \",\n          \"TRUMP OR HILLARY ? IM COMING , HARAMBE ! \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df['label'] = df['label'].apply(lambda x: 1 if x == 'offensive' else 0 if x == 'Non-offensiv' else x)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "I8YEwwAteydW",
        "outputId": "bdbe2eaf-1995-4f84-e2ba-18e8f85a435c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    440\n",
              "1    303\n",
              "Name: label, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u9zJqsHGeydX"
      },
      "outputs": [],
      "source": [
        "df_minor = df[df['label'] == 0]\n",
        "df_mayor = df[df['label'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "UN6umnJFeydY",
        "outputId": "a9896fe4-3ed4-4339-f45d-6b52a42ea79a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    303\n",
              "0    303\n",
              "Name: label, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_upsampling = resample(df_minor, n_samples=len(df_mayor), random_state=42)\n",
        "df = pd.concat([df_mayor, df_upsampling]).reset_index(drop=True)\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-9eO9vlgeyda"
      },
      "outputs": [],
      "source": [
        "# Tentukan path lengkap ke folder Data_2\n",
        "folder_path = '/content/pipeline_2/Data_2'\n",
        "\n",
        "# Periksa apakah folder sudah ada\n",
        "if not os.path.exists(folder_path):\n",
        "    # Jika belum ada, buat folder baru\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Simpan DataFrame ke file CSV di dalam folder Data_2\n",
        "df.to_csv(os.path.join(folder_path, 'processed_dataset.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITA5EHTLeydb"
      },
      "source": [
        "## Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "82SAwbd3eydb",
        "outputId": "bece5b88-493e-496e-ec5a-b77a0ab73632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Pipeline storage path set to: mhmmadgiatt-pipeline/hate-speech-pipeline\n",
            "INFO:absl:Generating ephemeral wheel package for '/content/pipeline_2/modules/hate_transform.py' (including modules: ['hate_transform', 'hate_trainer', 'components']).\n",
            "INFO:absl:User module package has hash fingerprint version 99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '/tmp/tmpqqdr7jrt/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpa2rqagcn', '--dist-dir', '/tmp/tmpiij6hzz_']\n",
            "INFO:absl:Successfully built user code wheel distribution at 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'; target user module is 'hate_transform'.\n",
            "INFO:absl:Full user module path is 'hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'\n",
            "INFO:absl:Generating ephemeral wheel package for '/content/pipeline_2/modules/hate_trainer.py' (including modules: ['hate_transform', 'hate_trainer', 'components']).\n",
            "INFO:absl:User module package has hash fingerprint version 99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '/tmp/tmp4mlbyij7/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpmx76o7ku', '--dist-dir', '/tmp/tmpsh76c_j6']\n",
            "INFO:absl:Successfully built user code wheel distribution at 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'; target user module is 'hate_trainer'.\n",
            "INFO:absl:Full user module path is 'hate_trainer@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'\n",
            "INFO:absl:Using deployment config:\n",
            " executor_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
            "      }\n",
            "      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n",
            "      beam_pipeline_args: \"--direct_num_workers=0\"\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_running_mode=multi_processing\"\n",
            "        }\n",
            "      }\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_num_workers=0\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Evaluator\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.evaluator.executor.Executor\"\n",
            "      }\n",
            "      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n",
            "      beam_pipeline_args: \"--direct_num_workers=0\"\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_running_mode=multi_processing\"\n",
            "        }\n",
            "      }\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_num_workers=0\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"ExampleValidator\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Pusher\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"SchemaGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"StatisticsGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
            "      }\n",
            "      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n",
            "      beam_pipeline_args: \"--direct_num_workers=0\"\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_running_mode=multi_processing\"\n",
            "        }\n",
            "      }\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_num_workers=0\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Trainer\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Transform\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.transform.executor.Executor\"\n",
            "      }\n",
            "      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n",
            "      beam_pipeline_args: \"--direct_num_workers=0\"\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_running_mode=multi_processing\"\n",
            "        }\n",
            "      }\n",
            "      beam_pipeline_args_placeholders {\n",
            "        value {\n",
            "          string_value: \"--direct_num_workers=0\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "custom_driver_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "metadata_connection_config {\n",
            "  database_connection_config {\n",
            "    sqlite {\n",
            "      filename_uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/metadata.sqlite\"\n",
            "      connection_mode: READWRITE_OPENCREATE\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using connection config:\n",
            " sqlite {\n",
            "  filename_uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/metadata.sqlite\"\n",
            "  connection_mode: READWRITE_OPENCREATE\n",
            "}\n",
            "\n",
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Node CsvExampleGen depends on [].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node CsvExampleGen is scheduled.\n",
            "INFO:absl:Node Latest_blessed_model_resolver depends on [].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Latest_blessed_model_resolver is scheduled.\n",
            "INFO:absl:Node StatisticsGen depends on ['Run[CsvExampleGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node StatisticsGen is scheduled.\n",
            "INFO:absl:Node SchemaGen depends on ['Run[StatisticsGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node SchemaGen is scheduled.\n",
            "INFO:absl:Node ExampleValidator depends on ['Run[SchemaGen]', 'Run[StatisticsGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node ExampleValidator is scheduled.\n",
            "INFO:absl:Node Transform depends on ['Run[CsvExampleGen]', 'Run[SchemaGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Transform is scheduled.\n",
            "INFO:absl:Node Trainer depends on ['Run[SchemaGen]', 'Run[Transform]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Trainer is scheduled.\n",
            "INFO:absl:Node Evaluator depends on ['Run[CsvExampleGen]', 'Run[Latest_blessed_model_resolver]', 'Run[Trainer]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Evaluator is scheduled.\n",
            "INFO:absl:Node Pusher depends on ['Run[Evaluator]', 'Run[Trainer]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Pusher is scheduled.\n",
            "INFO:absl:node Latest_blessed_model_resolver is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
            "  }\n",
            "  id: \"Latest_blessed_model_resolver\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Latest_blessed_model_resolver\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"_generated_model_3\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      hidden: true\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"_generated_modelblessing_4\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      hidden: true\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      input_graph_ref {\n",
            "        graph_id: \"graph_1\"\n",
            "        key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      input_graph_ref {\n",
            "        graph_id: \"graph_1\"\n",
            "        key: \"model_blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  input_graphs {\n",
            "    key: \"graph_1\"\n",
            "    value {\n",
            "      nodes {\n",
            "        key: \"dict_2\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_MULTIMAP\n",
            "          dict_node {\n",
            "            node_ids {\n",
            "              key: \"model\"\n",
            "              value: \"input_3\"\n",
            "            }\n",
            "            node_ids {\n",
            "              key: \"model_blessing\"\n",
            "              value: \"input_4\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"input_3\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_LIST\n",
            "          input_node {\n",
            "            input_key: \"_generated_model_3\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"input_4\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_LIST\n",
            "          input_node {\n",
            "            input_key: \"_generated_modelblessing_4\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"op_1\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_MULTIMAP\n",
            "          op_node {\n",
            "            op_type: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
            "            args {\n",
            "              node_id: \"dict_2\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      result_node: \"op_1\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Running as an resolver node.\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:[Latest_blessed_model_resolver] Resolved inputs: ({'model': [], 'model_blessing': []},)\n",
            "INFO:absl:node Latest_blessed_model_resolver is finished.\n",
            "INFO:absl:node CsvExampleGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/content/pipeline_2/Data_2\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_file_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 5\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:[CsvExampleGen] Resolved inputs: ({},)\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 2\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]}), exec_properties={'output_data_format': 6, 'input_base': '/content/pipeline_2/Data_2', 'output_file_format': 5, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 8,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/.system/stateful_working_dir/e0a8ac9f-9a42-4a11-9c14-a8d334ffe3c0', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/content/pipeline_2/Data_2\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_file_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 5\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.10/dist-packages/tfx to temp dir /tmp/tmpchvek66v/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpchvek66v/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpchvek66v/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpchvek66v/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
            "INFO:absl:Generating examples.\n",
            "INFO:absl:Processing input csv data /content/pipeline_2/Data_2/* to TFExample.\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661408   nanos: 602433443 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661408   nanos: 612411022 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661408   nanos: 602433443 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661408   nanos: 611761569 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661417   nanos: 721674680 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_15\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661417   nanos: 794029474 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_14\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
            "INFO:absl:Examples generated.\n",
            "INFO:absl:Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
            "INFO:absl:Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 2 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/.system/stateful_working_dir/e0a8ac9f-9a42-4a11-9c14-a8d334ffe3c0\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]}) for execution 2\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node CsvExampleGen is finished.\n",
            "INFO:absl:node StatisticsGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"SchemaGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 3\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/.system/stateful_working_dir/4cf39632-f167-43e6-b72f-2de1a79daa88', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"SchemaGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.10/dist-packages/tfx to temp dir /tmp/tmp3f_07lmo/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp3f_07lmo/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp3f_07lmo/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp3f_07lmo/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
            "INFO:absl:Generating statistics for split train.\n",
            "INFO:absl:Statistics for split train written to mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3/Split-train.\n",
            "INFO:absl:Generating statistics for split eval.\n",
            "INFO:absl:Statistics for split eval written to mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3/Split-eval.\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661431   nanos: 27925014 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661431   nanos: 36211252 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661431   nanos: 157655954 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661431   nanos: 166802406 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661440   nanos: 410014629 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_47\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661440   nanos: 417198896 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_48\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 3 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/.system/stateful_working_dir/4cf39632-f167-43e6-b72f-2de1a79daa88\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")]}) for execution 3\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node StatisticsGen is finished.\n",
            "INFO:absl:node SchemaGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"SchemaGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"infer_feature_shape\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733661445950\n",
            "last_update_time_since_epoch: 1733661445950\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 4\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733661445950\n",
            "last_update_time_since_epoch: 1733661445950\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}), exec_properties={'exclude_splits': '[]', 'infer_feature_shape': 1}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/.system/executor_execution/4/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/.system/stateful_working_dir/1d524b77-55ca-46e7-bc39-0f9f5e46a73c', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"SchemaGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"infer_feature_shape\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Processing schema from statistics for split train.\n",
            "INFO:absl:Processing schema from statistics for split eval.\n",
            "INFO:absl:Schema written to mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4/schema.pbtxt.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 4 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/.system/stateful_working_dir/1d524b77-55ca-46e7-bc39-0f9f5e46a73c\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}) for execution 4\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node SchemaGen is finished.\n",
            "INFO:absl:node Transform is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.transform.component.Transform\"\n",
            "    base_type: TRANSFORM\n",
            "  }\n",
            "  id: \"Transform\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Transform\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"post_transform_anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformGraph\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transformed_examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"updated_analyzer_cache\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformCache\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"disable_statistics\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"force_tf_compat_v1\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Transform] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 5\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=5, input_dict={'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'post_transform_stats': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_stats/5\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_stats': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/pre_transform_stats/5\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/pre_transform_schema/5\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'post_transform_schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_schema/5\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'transformed_examples': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transformed_examples/5\"\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_anomalies/5\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/updated_analyzer_cache/5\"\n",
            ", artifact_type: name: \"TransformCache\"\n",
            ")], 'transform_graph': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transform_graph/5\"\n",
            ", artifact_type: name: \"TransformGraph\"\n",
            ")]}), exec_properties={'force_tf_compat_v1': 0, 'custom_config': 'null', 'module_path': 'hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl', 'disable_statistics': 0}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/.system/executor_execution/5/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/.system/stateful_working_dir/fa1e258f-fcb4-43ca-8d42-66f8792e8f0c', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/.system/executor_execution/5/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.transform.component.Transform\"\n",
            "    base_type: TRANSFORM\n",
            "  }\n",
            "  id: \"Transform\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Transform\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"post_transform_anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformGraph\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transformed_examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"updated_analyzer_cache\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformCache\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"disable_statistics\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"force_tf_compat_v1\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.10/dist-packages/tfx to temp dir /tmp/tmph67cmcr7/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmph67cmcr7/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmph67cmcr7/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmph67cmcr7/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
            "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
            "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
            "INFO:absl:Installing 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpcvovsvzv', 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'.\n",
            "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'hate_transform@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
            "INFO:absl:Installing 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpei87r3_g', 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'.\n",
            "INFO:absl:Installing 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmp12kf9qk5', 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Transform-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661471   nanos: 458820819 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661471   nanos: 467043876 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661471   nanos: 525702953 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661471   nanos: 533537626 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661483   nanos: 229615688 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_181\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661483   nanos: 335660696 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_182\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 5 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/.system/stateful_working_dir/fa1e258f-fcb4-43ca-8d42-66f8792e8f0c\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'post_transform_stats': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_stats/5\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_stats': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/pre_transform_stats/5\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/pre_transform_schema/5\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'post_transform_schema': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_schema/5\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'transformed_examples': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transformed_examples/5\"\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/post_transform_anomalies/5\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/updated_analyzer_cache/5\"\n",
            ", artifact_type: name: \"TransformCache\"\n",
            ")], 'transform_graph': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transform_graph/5\"\n",
            ", artifact_type: name: \"TransformGraph\"\n",
            ")]}) for execution 5\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Transform is finished.\n",
            "INFO:absl:node ExampleValidator is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
            "  }\n",
            "  id: \"ExampleValidator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.ExampleValidator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[ExampleValidator] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733661445950\n",
            "last_update_time_since_epoch: 1733661445950\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 6\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=6, input_dict={'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733661445950\n",
            "last_update_time_since_epoch: 1733661445950\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/anomalies/6\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/.system/executor_execution/6/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/.system/stateful_working_dir/6e75511e-643e-47a2-b19b-ec76c2e04e6a', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/.system/executor_execution/6/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
            "  }\n",
            "  id: \"ExampleValidator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.ExampleValidator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Validating schema against the computed statistics for split train.\n",
            "INFO:absl:Anomalies alerts created for split train.\n",
            "INFO:absl:Validation complete for split train. Anomalies written to mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/anomalies/6/Split-train.\n",
            "INFO:absl:Validating schema against the computed statistics for split eval.\n",
            "INFO:absl:Anomalies alerts created for split eval.\n",
            "INFO:absl:Validation complete for split eval. Anomalies written to mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/anomalies/6/Split-eval.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 6 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/.system/stateful_working_dir/6e75511e-643e-47a2-b19b-ec76c2e04e6a\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/ExampleValidator/anomalies/6\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")]}) for execution 6\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node ExampleValidator is finished.\n",
            "INFO:absl:node Trainer is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "    base_type: TRAIN\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"hate_trainer@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Trainer] Resolved inputs: ({'transform_graph': [Artifact(artifact: id: 11\n",
            "type_id: 24\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transform_graph/5\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733661492044\n",
            "last_update_time_since_epoch: 1733661492044\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")], 'examples': [Artifact(artifact: id: 8\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transformed_examples/5\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661492044\n",
            "last_update_time_since_epoch: 1733661492044\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 7\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'transform_graph': [Artifact(artifact: id: 11\n",
            "type_id: 24\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transform_graph/5\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733661492044\n",
            "last_update_time_since_epoch: 1733661492044\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")], 'examples': [Artifact(artifact: id: 8\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Transform/transformed_examples/5\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661492044\n",
            "last_update_time_since_epoch: 1733661492044\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733661446464\n",
            "last_update_time_since_epoch: 1733661446464\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            ", artifact_type: name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'model_run': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model_run/7\"\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")]}), exec_properties={'train_args': '{\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'eval_args': '{\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'module_path': 'hate_trainer@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl', 'custom_config': 'null'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/.system/executor_execution/7/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/.system/stateful_working_dir/07e5ccb9-607d-47c0-bd85-c58d41e1fece', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "    base_type: TRAIN\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"hate_trainer@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:udf_utils.get_fn {'train_args': '{\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'eval_args': '{\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'module_path': 'hate_trainer@mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl', 'custom_config': 'null'} 'run_fn'\n",
            "INFO:absl:Installing 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpk9ws5z4b', 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'mhmmadgiatt-pipeline/hate-speech-pipeline/_wheels/tfx_user_code_Trainer-0.0+99efbab93e16c38c5b828d267e21ab23828c87993eb3f5d8ad2d2d27983bf3d5-py3-none-any.whl'.\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sentence_xf (InputLayer)    [(None, 1)]               0         \n",
            "                                                                 \n",
            " tf.reshape (TFOpLambda)     (None,)                   0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 50)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 50, 32)            1600000   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 32)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1614593 (6.16 MB)\n",
            "Trainable params: 1614593 (6.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.7689\n",
            "Epoch 1: val_binary_accuracy improved from -inf to 0.54026, saving model to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 7672, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_none_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_7672, model_dense_3_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 6s 145ms/step - loss: 0.4859 - binary_accuracy: 0.7750 - val_loss: 1.6970 - val_binary_accuracy: 0.5403\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0554 - binary_accuracy: 0.9787\n",
            "Epoch 2: val_binary_accuracy improved from 0.54026 to 0.57143, saving model to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 9725, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_9725, model_dense_3_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 103ms/step - loss: 0.0554 - binary_accuracy: 0.9787 - val_loss: 1.6087 - val_binary_accuracy: 0.5714\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0178 - binary_accuracy: 0.9944\n",
            "Epoch 3: val_binary_accuracy did not improve from 0.57143\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.0178 - binary_accuracy: 0.9944 - val_loss: 1.7283 - val_binary_accuracy: 0.5461\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0142 - binary_accuracy: 0.9956\n",
            "Epoch 4: val_binary_accuracy did not improve from 0.57143\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.0142 - binary_accuracy: 0.9956 - val_loss: 1.7255 - val_binary_accuracy: 0.5331\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0153 - binary_accuracy: 0.9969\n",
            "Epoch 5: val_binary_accuracy did not improve from 0.57143\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.0153 - binary_accuracy: 0.9969 - val_loss: 1.4054 - val_binary_accuracy: 0.5253\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0127 - binary_accuracy: 0.9962\n",
            "Epoch 6: val_binary_accuracy improved from 0.57143 to 0.58961, saving model to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 14414, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_14414, model_dense_3_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 112ms/step - loss: 0.0127 - binary_accuracy: 0.9962 - val_loss: 2.2145 - val_binary_accuracy: 0.5896\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0113 - binary_accuracy: 0.9956\n",
            "Epoch 7: val_binary_accuracy improved from 0.58961 to 0.59156, saving model to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 16418, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_16418, model_dense_3_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 167ms/step - loss: 0.0113 - binary_accuracy: 0.9956 - val_loss: 1.8123 - val_binary_accuracy: 0.5916\n",
            "Epoch 8/10\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.0094 - binary_accuracy: 0.9961\n",
            "Epoch 8: val_binary_accuracy did not improve from 0.59156\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.0097 - binary_accuracy: 0.9956 - val_loss: 1.9119 - val_binary_accuracy: 0.4974\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0065 - binary_accuracy: 0.9956\n",
            "Epoch 9: val_binary_accuracy did not improve from 0.59156\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.0065 - binary_accuracy: 0.9956 - val_loss: 2.3323 - val_binary_accuracy: 0.5266\n",
            "Epoch 10/10\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.0069 - binary_accuracy: 0.9980\n",
            "Epoch 10: val_binary_accuracy did not improve from 0.59156\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 0.0068 - binary_accuracy: 0.9981 - val_loss: 2.6621 - val_binary_accuracy: 0.5721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Feature image_name has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature sentence has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Function `serve_tf_examples_fn` contains input name(s) table_handle, 20286, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_20286, model_dense_3_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb\n",
            "INFO:absl:Training complete. Model written to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving. ModelRun written to mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model_run/7\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 7 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/.system/stateful_working_dir/07e5ccb9-607d-47c0-bd85-c58d41e1fece\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            ", artifact_type: name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'model_run': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model_run/7\"\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")]}) for execution 7\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Trainer is finished.\n",
            "INFO:absl:node Evaluator is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "    base_type: EVALUATE\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Latest_blessed_model_resolver\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Latest_blessed_model_resolver\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalsePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TruePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalseNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TrueNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"label\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"fairness_indicator_thresholds\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Evaluator] Resolved inputs: ({'model': [Artifact(artifact: id: 13\n",
            "type_id: 27\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733661526113\n",
            "last_update_time_since_epoch: 1733661526113\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'baseline_model': []},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 8\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'model': [Artifact(artifact: id: 13\n",
            "type_id: 27\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733661526113\n",
            "last_update_time_since_epoch: 1733661526113\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:151505,xor_checksum:1733661391,sum_checksum:1733661391\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733661422384\n",
            "last_update_time_since_epoch: 1733661422384\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'baseline_model': []}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/evaluation/8\"\n",
            ", artifact_type: name: \"ModelEvaluation\"\n",
            ")], 'blessing': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/blessing/8\"\n",
            ", artifact_type: name: \"ModelBlessing\"\n",
            ")]}), exec_properties={'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/.system/executor_execution/8/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/.system/stateful_working_dir/5347b1b4-bed1-4f31-bc41-047e7cfda33e', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "    base_type: EVALUATE\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Latest_blessed_model_resolver\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Latest_blessed_model_resolver\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalsePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TruePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalseNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TrueNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"label\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"fairness_indicator_thresholds\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.10/dist-packages/tfx to temp dir /tmp/tmpck2ppc0m/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpck2ppc0m/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpck2ppc0m/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpck2ppc0m/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
            "INFO:absl:udf_utils.get_fn {'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'} 'custom_eval_shared_model'\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7/Format-Serving as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n",
            "INFO:absl:udf_utils.get_fn {'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'} 'custom_extractors'\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "INFO:absl:eval_shared_models have model_types: {'tf_keras'}\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661537   nanos: 372214078 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661537   nanos: 381510972 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661537   nanos: 415510892 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661537   nanos: 423435926 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661552   nanos: 77368259 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_298\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1733661552   nanos: 300504922 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_299\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
            "INFO:absl:Evaluation complete. Results written to mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/evaluation/8.\n",
            "INFO:absl:Checking validation results.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "INFO:absl:Blessing result True written to mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/blessing/8.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 8 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/.system/stateful_working_dir/5347b1b4-bed1-4f31-bc41-047e7cfda33e\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/evaluation/8\"\n",
            ", artifact_type: name: \"ModelEvaluation\"\n",
            ")], 'blessing': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/blessing/8\"\n",
            ", artifact_type: name: \"ModelBlessing\"\n",
            ")]}) for execution 8\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Evaluator is finished.\n",
            "INFO:absl:node Pusher is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "    base_type: DEPLOY\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Evaluator\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Evaluator\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"mhmmadgiatt-pipeline/exported_model\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Evaluator\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Pusher] Resolved inputs: ({'model_blessing': [Artifact(artifact: id: 16\n",
            "type_id: 31\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/blessing/8\"\n",
            "custom_properties {\n",
            "  key: \"blessed\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model\"\n",
            "  value {\n",
            "    string_value: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model_id\"\n",
            "  value {\n",
            "    int_value: 13\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ModelBlessing\"\n",
            "create_time_since_epoch: 1733661567896\n",
            "last_update_time_since_epoch: 1733661567896\n",
            ", artifact_type: id: 31\n",
            "name: \"ModelBlessing\"\n",
            ")], 'model': [Artifact(artifact: id: 13\n",
            "type_id: 27\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733661526113\n",
            "last_update_time_since_epoch: 1733661526113\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 9\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'model_blessing': [Artifact(artifact: id: 16\n",
            "type_id: 31\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Evaluator/blessing/8\"\n",
            "custom_properties {\n",
            "  key: \"blessed\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model\"\n",
            "  value {\n",
            "    string_value: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model_id\"\n",
            "  value {\n",
            "    int_value: 13\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ModelBlessing\"\n",
            "create_time_since_epoch: 1733661567896\n",
            "last_update_time_since_epoch: 1733661567896\n",
            ", artifact_type: id: 31\n",
            "name: \"ModelBlessing\"\n",
            ")], 'model': [Artifact(artifact: id: 13\n",
            "type_id: 27\n",
            "uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Trainer/model/7\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733661526113\n",
            "last_update_time_since_epoch: 1733661526113\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/pushed_model/9\"\n",
            ", artifact_type: name: \"PushedModel\"\n",
            "base_type: MODEL\n",
            ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"mhmmadgiatt-pipeline/exported_model\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/.system/executor_execution/9/executor_output.pb', stateful_working_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/.system/stateful_working_dir/117e211c-43a7-4d17-b78d-0984a8839e86', tmp_dir='mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "    base_type: DEPLOY\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241208-123639.482957\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"hate-speech-pipeline.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Evaluator\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241208-123639.482957\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"hate-speech-pipeline.Evaluator\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"mhmmadgiatt-pipeline/exported_model\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Evaluator\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"hate-speech-pipeline\"\n",
            ", pipeline_run_id='20241208-123639.482957', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Model version: 1733661568\n",
            "INFO:absl:Model written to serving path mhmmadgiatt-pipeline/exported_model/1733661568.\n",
            "INFO:absl:Model pushed to mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/pushed_model/9.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 9 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/.system/stateful_working_dir/117e211c-43a7-4d17-b78d-0984a8839e86\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"mhmmadgiatt-pipeline/hate-speech-pipeline/Pusher/pushed_model/9\"\n",
            ", artifact_type: name: \"PushedModel\"\n",
            "base_type: MODEL\n",
            ")]}) for execution 9\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Pusher is finished.\n"
          ]
        }
      ],
      "source": [
        "PIPELINE_IDENTIFIER = \"hate-speech-pipeline\"\n",
        "\n",
        "DATA_SOURCE = \"/content/pipeline_2/Data_2\"\n",
        "TRANSFORM_SCRIPT = \"/content/pipeline_2/modules/hate_transform.py\"\n",
        "TRAINING_SCRIPT = \"/content/pipeline_2/modules/hate_trainer.py\"\n",
        "\n",
        "BASE_OUTPUT_PATH = \"mhmmadgiatt-pipeline\"\n",
        "exported_model_dir = os.path.join(BASE_OUTPUT_PATH, 'exported_model')\n",
        "pipeline_storage = os.path.join(BASE_OUTPUT_PATH, PIPELINE_IDENTIFIER)\n",
        "metadata_database = os.path.join(pipeline_storage, \"metadata.sqlite\")\n",
        "\n",
        "\n",
        "def configure_local_pipeline(\n",
        "    pipeline_components, storage_path: Text\n",
        ") -> pipeline.Pipeline:\n",
        "\n",
        "    logging.info(f\"Pipeline storage path set to: {storage_path}\")\n",
        "    execution_args = [\n",
        "        \"--direct_running_mode=multi_processing\",\n",
        "        \"--direct_num_workers=0\"\n",
        "    ]\n",
        "\n",
        "    return pipeline.Pipeline(\n",
        "        pipeline_name=PIPELINE_IDENTIFIER,\n",
        "        pipeline_root=storage_path,\n",
        "        components=pipeline_components,\n",
        "        enable_cache=True,\n",
        "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
        "            metadata_database\n",
        "        ),\n",
        "        beam_pipeline_args=execution_args\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.set_verbosity(logging.INFO)\n",
        "\n",
        "    pipeline_components = init_components(\n",
        "        DATA_SOURCE,\n",
        "        training_module=TRAINING_SCRIPT,\n",
        "        transform_module=TRANSFORM_SCRIPT,\n",
        "        serving_model_dir=exported_model_dir,\n",
        "    )\n",
        "\n",
        "    pipeline_instance = configure_local_pipeline(pipeline_components, pipeline_storage)\n",
        "    BeamDagRunner().run(pipeline=pipeline_instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selesai - Pipeline Telah Dijalankan"
      ],
      "metadata": {
        "id": "bPgLjayUSQt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path folder pipeline yang ingin di-zip\n",
        "source_folder = '/content/mhmmadgiatt-pipeline'\n",
        "\n",
        "# Nama file zip output\n",
        "output_zip = '/content/mhmmadgiatt-pipeline.zip'\n",
        "\n",
        "# Membuat file zip dari folder pipeline\n",
        "shutil.make_archive(base_name=output_zip.replace('.zip', ''), format='zip', root_dir=source_folder)\n",
        "\n",
        "print(f\"Pipeline berhasil di-zip: {output_zip}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0a8IixYSaE2",
        "outputId": "9f35f570-d5fc-4e77-ca96-79cb5fecbcdd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline berhasil di-zip: /content/mhmmadgiatt-pipeline.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File zip yang berisi pipeline yang telah dijalankan dapat diunduh untuk keperluan distribusi atau pengarsipan."
      ],
      "metadata": {
        "id": "8G4p2frhSmQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Mendownload file zip\n",
        "files.download(output_zip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SK633TeJSm2V",
        "outputId": "bf6b2031-cc10-4914-aa0f-941278c8ac4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e56fcd20-081a-4c0c-a773-b8cb530dec9c\", \"mhmmadgiatt-pipeline.zip\", 22208286)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}